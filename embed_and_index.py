import os
import pandas as pd
import pickle
from langchain_community.vectorstores import FAISS
from langchain.docstore.document import Document
from langchain_huggingface import HuggingFaceEmbeddings

# è·¯å¾‘è¨­å®šï¼ˆçµ±ä¸€èˆ‡ query.py ç›¸åŒï¼‰
EXCEL_PATH = "SOP_çŸ¥è­˜åº«å»ºæ§‹æ¨¡æ¿.xlsx"
INDEX_FILE = "faiss_index"     # å„²å­˜å‘é‡è³‡æ–™å¤¾
DOCS_FILE = "docs.pkl"         # å„²å­˜åŸå§‹æ–‡ä»¶è³‡æ–™

# è®€å– Excel
df = pd.read_excel(EXCEL_PATH)

# è³‡æ–™è½‰æ›
docs = []
for _, row in df.iterrows():
    category = str(row.get("åˆ†é¡", "")).strip()
    issue = str(row.get("å¸¸è¦‹å•é¡Œ", "")).strip()
    context = str(row.get("æƒ…å¢ƒæè¿°ï¼ˆé¸å¡«ï¼‰", "")).strip()
    solution = str(row.get("æ¨™æº–ä½œæ³•æˆ–å»ºè­°å°ç­–", "")).strip()
    reference = str(row.get("åƒè€ƒæ–‡ä»¶/é æ•¸", "")).strip()
    remark = str(row.get("å‚™è¨»", "")).strip()

    content = f"""åˆ†é¡ï¼š{category}
å¸¸è¦‹å•é¡Œï¼š{issue}
æƒ…å¢ƒæè¿°ï¼š{context}
æ¨™æº–ä½œæ³•æˆ–å»ºè­°å°ç­–ï¼š{solution}
åƒè€ƒæ–‡ä»¶/é æ•¸ï¼š{reference}
å‚™è¨»ï¼š{remark}"""

    metadata = {"åˆ†é¡": category, "å¸¸è¦‹å•é¡Œ": issue}
    docs.append(Document(page_content=content, metadata=metadata))

# å»ºç«‹å‘é‡åº«
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
db = FAISS.from_documents(docs, embedding_model)

# å„²å­˜å‘é‡åº«
db.save_local(INDEX_FILE)
with open(DOCS_FILE, "wb") as f:
    pickle.dump(docs, f)

print("âœ… çŸ¥è­˜åº«å»ºæ§‹å®Œæˆï¼å…±å»ºç«‹ %d ç­†è³‡æ–™ã€‚" % len(docs))
print(f"ğŸ“‚ å‘é‡åº«å·²å„²å­˜åœ¨ï¼š{INDEX_FILE}")
